{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yumlembam/Basic-CNN/blob/master/Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "W7xfpyj4EWmy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tO7NYosYEisB",
        "colab_type": "code",
        "outputId": "4c1f5e67-09a4-4584-f80f-ad46428e2a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "Single_channel_slice = np.random.randn(3,4) # single channel matrix\n",
        "Single_channel_W = np.random.randn(2,2)\n",
        "Single_channel_b = np.random.randn(1,1)\n",
        "print(\"Single channel slice\", Single_channel_slice)\n",
        "print(\"Single Channel slice\",Single_channel_W)\n",
        "print(\"bias of single channel\",Single_channel_b) # Bias is not use here\n",
        "\n",
        "plt.imshow(Single_channel_slice, interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single channel slice [[ 1.62434536 -0.61175641 -0.52817175 -1.07296862]\n",
            " [ 0.86540763 -2.3015387   1.74481176 -0.7612069 ]\n",
            " [ 0.3190391  -0.24937038  1.46210794 -2.06014071]]\n",
            "Single Channel slice [[-0.3224172  -0.38405435]\n",
            " [ 1.13376944 -1.09989127]]\n",
            "bias of single channel [[-0.17242821]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAD0CAYAAAAIYOQEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZ1l3K486AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CnH5BHVZW91G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Single Channel Convolution"
      ]
    },
    {
      "metadata": {
        "id": "mdB8qlJHEtzN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convolution operation **S(i,j) = (I*k)(i,j)=$\\sum_{m=o}^k$$\\sum_{n=0}^q$I(i+m,j+n)K(m,n)**"
      ]
    },
    {
      "metadata": {
        "id": "JTyIhtpwJB7I",
        "colab_type": "code",
        "outputId": "6d30b405-d301-4b02-b0da-17c75dd6b671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "Z = np.zeros((2,3))\n",
        "print(Z)\n",
        "for i in range(0,2): # number of down sliding\n",
        "  for j in range (0,3): # number of side sliding\n",
        "    for m in range (0,2): # height of the kerel\n",
        "      for n in range(0,2): # width of the kernel\n",
        "        Z[i,j] = Z[i,j] + Single_channel_slice[i+m,j+n]*Single_channel_W[m,n]\n",
        "        \n",
        "print(\"Result of convolution\",Z)\n",
        "\n",
        "plt.imshow(Z, interpolation='nearest')\n",
        "plt.show()\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "Result of convolution [[ 3.22384586 -4.12843001  3.39782902]\n",
            " [ 1.24089073 -1.81893515  3.65341157]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAADdCAYAAADQI0sNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9YpD1YA-XJMy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Multi Channel Convolution"
      ]
    },
    {
      "metadata": {
        "id": "5KUwSBvx0Dq3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Software implementation usually works with 4-D tensors,with fourth axis indexing different examples in the batch\n",
        "\n",
        "Assume we have a 4-D kernel tensor K with element Ki,j,k,l giving the connection\n",
        "strength between a unit in channel i of the output and a unit in channel j of the\n",
        "input, with an offset of k rows and l columns between the output unit and the\n",
        "input unit. Assume our input consists of observed data V with element Vi,j,k giving\n",
        "the value of the input unit within channel i at row j and column k . Assume our\n",
        "output consists of Z with the same format as V. If Z is produced by convolving K\n",
        "across V without flipping K, then\n",
        "\n",
        "**$Z_{i},_{j},_{k}=\\sum_{l,m,n} V_{l},_{j+m-1},_{k+n-1}K_{i},_{l},_{m},_{n}$**\n",
        "\n",
        "\n",
        "\n",
        "In linear algebra notation, we index into\n",
        "arrays using a 1 for the first entry. This necessitates the −1 in the above formula. But in programming language like c we can just remove it.\n",
        "\n",
        "**$Z_{i},_{j},_{k}=\\sum_{l,m,n} V_{l},_{j+m},_{k+n}K_{i},_{l},_{m},_{n}$**"
      ]
    },
    {
      "metadata": {
        "id": "zTcEv57QSZuq",
        "colab_type": "code",
        "outputId": "f6309d17-b9de-4e10-8e82-5c36888c6935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "Multi_channel_slice = np.random.randn(3,3,4)\n",
        "Multi_channel_kernel = np.random.randn(1,3,2,2) # only one kernel in real convolution we need multiple kernel\n",
        "print(\"Multi Channel Slice\",Multi_channel_slice)\n",
        "print(\"Multi Channel Kernel\",Multi_channel_kernel)\n",
        "\n",
        "plt.imshow(Multi_channel_slice,interpolation='nearest')\n",
        "plt.show()\n",
        "\n",
        "print(\"Debugging\",Multi_channel_kernel[0,0,0,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Multi Channel Slice [[[ 1.62434536 -0.61175641 -0.52817175 -1.07296862]\n",
            "  [ 0.86540763 -2.3015387   1.74481176 -0.7612069 ]\n",
            "  [ 0.3190391  -0.24937038  1.46210794 -2.06014071]]\n",
            "\n",
            " [[-0.3224172  -0.38405435  1.13376944 -1.09989127]\n",
            "  [-0.17242821 -0.87785842  0.04221375  0.58281521]\n",
            "  [-1.10061918  1.14472371  0.90159072  0.50249434]]\n",
            "\n",
            " [[ 0.90085595 -0.68372786 -0.12289023 -0.93576943]\n",
            "  [-0.26788808  0.53035547 -0.69166075 -0.39675353]\n",
            "  [-0.6871727  -0.84520564 -0.67124613 -0.0126646 ]]]\n",
            "Multi Channel Kernel [[[[-1.11731035  0.2344157 ]\n",
            "   [ 1.65980218  0.74204416]]\n",
            "\n",
            "  [[-0.19183555 -0.88762896]\n",
            "   [-0.74715829  1.6924546 ]]\n",
            "\n",
            "  [[ 0.05080775 -0.63699565]\n",
            "   [ 0.19091548  2.10025514]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAD8CAYAAABkQFF6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvMui9C5nhTIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Debugging -1.1173103486352778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cF4kCSuF7_fL",
        "colab_type": "code",
        "outputId": "f9a4dadb-52a3-4602-c209-e779cd754f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "result_multichannel = np.zeros((1,2,3))\n",
        "print(result_multichannel)\n",
        "for i in range (0,1): # number of filter\n",
        "  for j in range (0,2): # number of down sliding\n",
        "    for k in range (0,3): # number of side sliding\n",
        "      for l in range (0,3): #number of channel in both input and kernel\n",
        "        for m in range(0,2):# kernel dimension\n",
        "          for n in range(0,2):\n",
        "            result_multichannel[i,j,k] = result_multichannel[i,j,k] + Multi_channel_slice[l,j+m,k+n]*Multi_channel_kernel[i,l,m,n]\n",
        "\n",
        "print(result_multichannel)\n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0.]\n",
            "  [0. 0. 0.]]]\n",
            "[[[-1.63985663 -3.47887792  4.0079552 ]\n",
            "  [ 0.15228802  3.34951337 -1.51560605]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2r8wDLGmZFhC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: zero_pad\n",
        "\n",
        "def zero_pad_try(X, pad):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
        "    as illustrated in Figure 1.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 1 line)\n",
        "    X_pad = np.pad(X, ((0, 0), (1, 1), (0, 0)), 'constant', constant_values=0)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xc6RQekejzCu",
        "colab_type": "code",
        "outputId": "9deffbce-d639-4ecb-f5b0-27b910bea831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "Zero_padded_multi_slice = zero_pad_try(Multi_channel_slice,2)\n",
        "print(Zero_padded_multi_slice)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0.          0.          0.          0.        ]\n",
            "  [ 1.62434536 -0.61175641 -0.52817175 -1.07296862]\n",
            "  [ 0.86540763 -2.3015387   1.74481176 -0.7612069 ]\n",
            "  [ 0.3190391  -0.24937038  1.46210794 -2.06014071]\n",
            "  [ 0.          0.          0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.          0.          0.        ]\n",
            "  [-0.3224172  -0.38405435  1.13376944 -1.09989127]\n",
            "  [-0.17242821 -0.87785842  0.04221375  0.58281521]\n",
            "  [-1.10061918  1.14472371  0.90159072  0.50249434]\n",
            "  [ 0.          0.          0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.          0.          0.        ]\n",
            "  [ 0.90085595 -0.68372786 -0.12289023 -0.93576943]\n",
            "  [-0.26788808  0.53035547 -0.69166075 -0.39675353]\n",
            "  [-0.6871727  -0.84520564 -0.67124613 -0.0126646 ]\n",
            "  [ 0.          0.          0.          0.        ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rZyRJ08Eor-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: zero_pad\n",
        "\n",
        "def zero_pad(X_value, pad_value):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
        "    as illustrated in Figure 1.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 1 line)\n",
        "    X_pad_value = np.pad(X_value, ((0, 0), (pad_value, pad_value), (pad_value, pad_value), (0, 0)), 'constant', constant_values=0)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X_pad_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w8U_naOorLnv",
        "colab_type": "code",
        "outputId": "85cb124e-88f7-4fcf-d87f-7ee95e770203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_pad(x, 2)\n",
        "print (\"x.shape =\", x.shape)\n",
        "print (\"x_pad.shape =\", x_pad.shape)\n",
        "print (\"x[1,1] =\", x[1,1])\n",
        "print (\"x_pad[1,1] =\", x_pad[0,1,])\n",
        "\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0,:,:,0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape = (4, 3, 3, 2)\n",
            "x_pad.shape = (4, 7, 7, 2)\n",
            "x[1,1] = [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] = [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7facbac56c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAACtCAYAAADBPaZCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GDdH9QqHMd2o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: conv_single_step\n",
        "\n",
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    \"\"\"\n",
        "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
        "    of the previous layer.\n",
        "    \n",
        "    Arguments:\n",
        "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
        "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
        "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "    \n",
        "    Returns:\n",
        "    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "    # Element-wise product between a_slice and W. Do not add the bias yet.\n",
        "    s = np.multiply(a_slice_prev, W)\n",
        "    # Sum over all entries of the volume s.\n",
        "    Z = np.sum(s)\n",
        "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
        "    Z = Z + float(b)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2bNBociMyfe",
        "colab_type": "code",
        "outputId": "2dd76bd9-fefb-4061-983d-a074c6480ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = -6.999089450680221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nHeCaidAT872",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: conv_forward\n",
        "\n",
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve dimensions from W's shape (≈1 line)\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)\n",
        "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
        "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
        "    \n",
        "    # Initialize the output volume Z with zeros. (≈1 line)\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Create A_prev_pad by padding A_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):                               # loop over the batch of training examples\n",
        "        a_prev_pad = A_prev_pad[i]                               # Select ith training example's padded activation\n",
        "        for h in range(n_H):                           # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                    \n",
        "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[...,c], b[...,c])\n",
        "                                        \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "    print(\"The shape of Z is\",Z.shape)\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    #print(\"printing cache\")\n",
        "    #print(cache)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iohXdPM0TWxf",
        "colab_type": "code",
        "outputId": "56f11cc2-0137-45e9-b9ab-59902359f6b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3893
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10,4,4,3)\n",
        "W = np.random.randn(2,2,3,8)\n",
        "b = np.random.randn(1,1,1,8)\n",
        "hparameters = {\"pad\" : 2,\n",
        "               \"stride\": 2}\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "print(\"The value of Z is\",Z)\n",
        "print(\"Z's mean =\", np.mean(Z))\n",
        "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
        "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of Z is (10, 4, 4, 8)\n",
            "The value of Z is [[[[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [ -5.62626365  -0.85327034   0.30276347 ...  -6.80726038\n",
            "     -1.23309753   2.64990283]\n",
            "   [  2.08987783  -2.79690946  -0.72067882 ...   6.32999645\n",
            "     -1.99398264   9.27399969]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [ -1.39647145  -6.02091128  -2.90853467 ...  -4.53265357\n",
            "     -1.03240479  -0.76496589]\n",
            "   [ -3.52376467   2.50067997  -3.70139219 ...   0.01735065\n",
            "     -3.80189413   1.17646803]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]]\n",
            "\n",
            "\n",
            " [[[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.08367282  -2.0808981   -4.16119517 ...  -1.78610875\n",
            "     -4.71325433  -0.89005663]\n",
            "   [ -2.64314518  -3.39898808  -4.28346842 ... -11.03958162\n",
            "     -3.06425905  -4.32330087]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  3.80661854  -1.41601581   0.17491281 ...   3.06829308\n",
            "     -5.17017132  -0.06196656]\n",
            "   [  3.1743111    2.06819111   2.46003515 ...   1.76088464\n",
            "     -1.36238193  -0.18849899]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]]\n",
            "\n",
            "\n",
            " [[[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  6.57668301   2.8664037    1.62844774 ...   3.84360661\n",
            "      2.02458263   0.37037825]\n",
            "   [ -2.51266463   4.27674681   5.47592653 ...   3.60263557\n",
            "      2.63476208   0.20217395]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.42803122  -2.91156919  -5.59192533 ...  -2.74759914\n",
            "      3.74298226  -3.1750521 ]\n",
            "   [  0.3496056    2.63006765   1.31273099 ...   5.53657922\n",
            "      2.38941362   3.56735666]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [ -4.82442663   6.98656048   7.23031333 ...  -1.40808109\n",
            "      0.24871714  -5.01082128]\n",
            "   [ -0.6558226   -0.19061003  -0.40510025 ...  -4.32270779\n",
            "     -1.51474856  -2.10605794]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.62108599   0.94141219   6.88848277 ...   6.2834709\n",
            "      0.65251537  -5.35154958]\n",
            "   [ -5.88214059  -3.23620939  -7.45265275 ... -10.73932285\n",
            "      1.5153822    3.05977144]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]]\n",
            "\n",
            "\n",
            " [[[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [ -0.01559053  -4.89997616  -7.94783728 ...  -4.62848751\n",
            "     -4.71879296   2.82504083]\n",
            "   [  3.51312201   2.63687545  -3.71737794 ... -10.60561888\n",
            "     -7.11664106  -4.22282051]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  3.99633307  -2.09374945  -0.50159351 ...   8.49748195\n",
            "      1.23102831   4.52254147]\n",
            "   [ -7.4569289    6.62314261   1.85070371 ...   2.15390642\n",
            "     -0.46165932   0.40872292]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]]\n",
            "\n",
            "\n",
            " [[[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  3.48293133  -5.12904196  -3.94459617 ...   4.08112577\n",
            "     -0.78145999   3.88336796]\n",
            "   [  5.46915059  -4.85239884  -2.18027586 ...  -0.11890473\n",
            "     -5.13429614  -3.02386617]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [ -5.40477325   2.7740254    2.0213699  ...   0.24223101\n",
            "     -4.46679098  -2.91579974]\n",
            "   [  7.85106555   1.63247963   1.48930852 ...   2.59150104\n",
            "      4.06848299   2.44036098]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]\n",
            "\n",
            "  [[  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]\n",
            "   [  0.37245685  -0.1484898   -0.1834002  ...  -0.6294416\n",
            "     -1.1134361   -0.06741002]]]]\n",
            "Z's mean = 0.048995203528855794\n",
            "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
            "  5.18531798  8.75898442]\n",
            "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k94xJPpkMxqB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: pool_forward\n",
        "\n",
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the forward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve dimensions from the input shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    for i in range(m):                         # loop over the training examples\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                for c in range (n_C):            # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                    \n",
        "                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.\n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(A.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    return A, cache\n",
        "            \n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-5znqMqNL08m",
        "colab_type": "code",
        "outputId": "eca52ca0-604a-4453-86b2-d8e04c95aaf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2,4,4,3)\n",
        "hparameters = {\"stride\":2, \"f\":2}\n",
        "A,cache = pool_forward(A_prev,hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A =\", A.shape)\n",
        "print(A)\n",
        "print()\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A =\", A.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A = (2, 2, 2, 3)\n",
            "[[[[ 1.62434536  0.86540763  1.13376944]\n",
            "   [ 1.74481176  1.46210794  0.50249434]]\n",
            "\n",
            "  [[ 0.90085595  0.2344157   1.65980218]\n",
            "   [-0.63699565  1.6924546   2.10025514]]]\n",
            "\n",
            "\n",
            " [[[ 0.12015895  1.25286816  0.51292982]\n",
            "   [ 1.13162939  1.51981682  2.18557541]]\n",
            "\n",
            "  [[ 0.37756379  0.87616892  1.12948391]\n",
            "   [ 1.19891788  0.76201118  0.41005165]]]]\n",
            "\n",
            "mode = average\n",
            "A = (2, 2, 2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5NA3iMbchDtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
        "               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    dW -- gradient of the cost with respect to the weights of the conv layer (W)\n",
        "          numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    db -- gradient of the cost with respect to the biases of the conv layer (b)\n",
        "          numpy array of shape (1, 1, 1, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve information from \"cache\"\n",
        "    (A_prev, W, b, hparameters) = cache\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve dimensions from W's shape\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    # Retrieve information from \"hparameters\"\n",
        "    stride = hparameters[\"stride\"]\n",
        "    pad = hparameters[\"pad\"]\n",
        "    \n",
        "    # Retrieve dimensions from dZ's shape\n",
        "    (m, n_H, n_W, n_C) = dZ.shape\n",
        "    \n",
        "    # Initialize dA_prev, dW, db with the correct shapes\n",
        "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
        "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
        "    db = np.zeros((1, 1, 1, n_C))\n",
        "\n",
        "    # Pad A_prev and dA_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
        "    \n",
        "    for i in range(m):                       # loop over the training examples\n",
        "        \n",
        "        # select ith training example from A_prev_pad and dA_prev_pad\n",
        "        a_prev_pad = A_prev_pad[i]\n",
        "        da_prev_pad = dA_prev_pad[i]\n",
        "        \n",
        "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):           # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = h\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Use the corners to define the slice from a_prev_pad\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "\n",
        "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
        "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
        "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
        "                    \n",
        "        # Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
        "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBY2uOUggu7k",
        "colab_type": "code",
        "outputId": "09b7d27c-7c82-4dec-8893-de5cd850c689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "dA,dW,db = conv_backward(Z,cache_conv)\n",
        "print(\"dA_mean =\", np.mean(dA))\n",
        "print(\"dW_mean =\", np.mean(dW))\n",
        "print(\"db_mean =\", np.mean(db))\n",
        "\n",
        "print(dA.shape)\n",
        "print(dW.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dA_mean = 0.6347704472654743\n",
            "dW_mean = 1.5572657428497354\n",
            "db_mean = 7.839232564616838\n",
            "(10, 4, 4, 3)\n",
            "(2, 2, 3, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fIBMwhbZ1SNM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Pooling layer backward pass"
      ]
    },
    {
      "metadata": {
        "id": "lzlM3lut1CVb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# max polling\n",
        "def create_mask_from_window(x):\n",
        "    \"\"\"\n",
        "    Creates a mask from an input matrix x, to identify the max entry of x.\n",
        "    \n",
        "    Arguments:\n",
        "    x -- Array of shape (f, f)\n",
        "    \n",
        "    Returns:\n",
        "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    mask = x == np.max(x)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNNqwQrA30id",
        "colab_type": "code",
        "outputId": "eb45e466-6bf4-4392-ec85-ed0f04ce240b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(2,3)\n",
        "mask = create_mask_from_window(x)\n",
        "print('x = ', x)\n",
        "print(\"mask = \", mask)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
            " [-1.07296862  0.86540763 -2.3015387 ]]\n",
            "mask =  [[ True False False]\n",
            " [False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n723dHCC33GD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Average pooling\n",
        "def distribute_value(dz, shape):\n",
        "    \"\"\"\n",
        "    Distributes the input value in the matrix of dimension shape\n",
        "    \n",
        "    Arguments:\n",
        "    dz -- input scalar\n",
        "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
        "    \n",
        "    Returns:\n",
        "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from shape (≈1 line)\n",
        "    (n_H, n_W) = shape\n",
        "    \n",
        "    # Compute the value to distribute on the matrix (≈1 line)\n",
        "    average = dz / (n_H * n_W)\n",
        "    \n",
        "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
        "    a = np.ones(shape) * average\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bCmsNMU94ra8",
        "colab_type": "code",
        "outputId": "fb60bb07-d3fa-4d82-b2cb-862637214749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "a = distribute_value(2, (2,2))\n",
        "print('distributed value =', a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distributed value = [[0.5 0.5]\n",
            " [0.5 0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_4hSRtUd4vRJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## puttiing it together:pooling backward\n",
        "def pool_backward(dA, cache, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the backward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
        "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Retrieve information from cache (≈1 line)\n",
        "    (A_prev, hparameters) = cache\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)\n",
        "    stride = hparameters[\"stride\"]\n",
        "    f = hparameters[\"f\"]\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
        "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
        "    m, n_H, n_W, n_C = dA.shape\n",
        "    \n",
        "    # Initialize dA_prev with zeros (≈1 line)\n",
        "    dA_prev = np.zeros(A_prev.shape)\n",
        "    \n",
        "    for i in range(m):                       # loop over the training examples\n",
        "        # select training example from A_prev (≈1 line)\n",
        "        a_prev = A_prev[i]\n",
        "        for h in range(n_H):                   # loop on the vertical axis\n",
        "            for w in range(n_W):               # loop on the horizontal axis\n",
        "                for c in range(n_C):           # loop over the channels (depth)\n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = h\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Compute the backward propagation in both modes.\n",
        "                    if mode == \"max\":\n",
        "                        # Use the corners and \"c\" to define the current slice from a_prev (≈1 line)\n",
        "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                        # Create the mask from a_prev_slice (≈1 line)\n",
        "                        mask = create_mask_from_window(a_prev_slice)\n",
        "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)\n",
        "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += np.multiply(mask, dA[i, h, w, c])\n",
        "                        \n",
        "                    elif mode == \"average\":\n",
        "                        # Get the value a from dA (≈1 line)\n",
        "                        da = dA[i, h, w, c]\n",
        "                        print(\"da shape\")\n",
        "                        print(da)\n",
        "                        # Define the shape of the filter as fxf (≈1 line)\n",
        "                        shape = (f, f)\n",
        "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)\n",
        "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += distribute_value(da, shape)\n",
        "                        \n",
        "    ### END CODE ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == A_prev.shape)\n",
        "    \n",
        "    return dA_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2ZH4FRI6_9p",
        "colab_type": "code",
        "outputId": "a41e0b64-bc90-4cdd-c07c-e505876b0ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2907
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(5, 5, 3, 2)\n",
        "hparameters = {\"stride\" : 1, \"f\": 2}\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "dA = np.random.randn(5, 4, 2, 2)\n",
        "\n",
        "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
        "print(\"mode = max\")\n",
        "print('mean of dA = ', np.mean(dA))\n",
        "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
        "\n",
        "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print('mean of dA = ', np.mean(dA))\n",
        "print('dA_prev[1,1] = ', dA_prev[1,1]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "mean of dA =  0.14571390272918056\n",
            "dA_prev[1,1] =  [[ 0.          0.        ]\n",
            " [ 5.05844394 -1.68282702]\n",
            " [ 0.          0.        ]]\n",
            "da shape\n",
            "-0.31011677351806\n",
            "da shape\n",
            "-2.434837764107139\n",
            "da shape\n",
            "1.038824601859414\n",
            "da shape\n",
            "2.1869796469742577\n",
            "da shape\n",
            "0.44136444356858207\n",
            "da shape\n",
            "-0.10015523328349978\n",
            "da shape\n",
            "-0.13644474389603303\n",
            "da shape\n",
            "-0.11905418777480989\n",
            "da shape\n",
            "0.0174094083000046\n",
            "da shape\n",
            "-1.1220187287468883\n",
            "da shape\n",
            "-0.5170944579202279\n",
            "da shape\n",
            "-0.997026827650263\n",
            "da shape\n",
            "0.2487991613877705\n",
            "da shape\n",
            "-0.29664115237086275\n",
            "da shape\n",
            "0.4952113239779604\n",
            "da shape\n",
            "-0.17470315974250095\n",
            "da shape\n",
            "0.9863351878212421\n",
            "da shape\n",
            "0.2135339013354418\n",
            "da shape\n",
            "2.1906997289697334\n",
            "da shape\n",
            "-1.8963609228910925\n",
            "da shape\n",
            "-0.646916688254908\n",
            "da shape\n",
            "0.901486891648711\n",
            "da shape\n",
            "2.528325706806398\n",
            "da shape\n",
            "-0.24863477771546005\n",
            "da shape\n",
            "0.043668993178389105\n",
            "da shape\n",
            "-0.22631424251360518\n",
            "da shape\n",
            "1.3314571125875918\n",
            "da shape\n",
            "-0.2873078634760189\n",
            "da shape\n",
            "0.6800698398781045\n",
            "da shape\n",
            "-0.3198015988986712\n",
            "da shape\n",
            "-1.2725587552459943\n",
            "da shape\n",
            "0.31354772046343216\n",
            "da shape\n",
            "0.5031848134353261\n",
            "da shape\n",
            "1.2932258825322618\n",
            "da shape\n",
            "-0.11044702641731631\n",
            "da shape\n",
            "-0.6173620637123609\n",
            "da shape\n",
            "0.5627610966190263\n",
            "da shape\n",
            "0.24073709223773224\n",
            "da shape\n",
            "0.28066507712263905\n",
            "da shape\n",
            "-0.07311270374727777\n",
            "da shape\n",
            "1.1603385699937696\n",
            "da shape\n",
            "0.36949271637572373\n",
            "da shape\n",
            "1.9046587083409812\n",
            "da shape\n",
            "1.1110566985605046\n",
            "da shape\n",
            "0.6590497961002102\n",
            "da shape\n",
            "-1.6274383406162574\n",
            "da shape\n",
            "0.602319280295629\n",
            "da shape\n",
            "0.42028220364705954\n",
            "da shape\n",
            "0.8109516728035557\n",
            "da shape\n",
            "1.0444420947072588\n",
            "da shape\n",
            "-0.40087819178892664\n",
            "da shape\n",
            "0.8240056184504077\n",
            "da shape\n",
            "-0.5623054310190898\n",
            "da shape\n",
            "1.9548780750090344\n",
            "da shape\n",
            "-1.3319516665172482\n",
            "da shape\n",
            "-1.7606885603987834\n",
            "da shape\n",
            "-1.6507212658241002\n",
            "da shape\n",
            "-0.8905555841630485\n",
            "da shape\n",
            "-1.119115398559728\n",
            "da shape\n",
            "1.956078903703642\n",
            "da shape\n",
            "-0.32649949807818424\n",
            "da shape\n",
            "-1.342675789377436\n",
            "da shape\n",
            "1.114382976779792\n",
            "da shape\n",
            "-0.5865239388215925\n",
            "da shape\n",
            "-1.2368533765413974\n",
            "da shape\n",
            "0.8758389276492995\n",
            "da shape\n",
            "0.6233621765780327\n",
            "da shape\n",
            "-0.4349566829552277\n",
            "da shape\n",
            "1.4075400002412286\n",
            "da shape\n",
            "0.12910157971072544\n",
            "da shape\n",
            "1.6169495988573002\n",
            "da shape\n",
            "0.5027408819999043\n",
            "da shape\n",
            "1.5588055406198593\n",
            "da shape\n",
            "0.10940269642542817\n",
            "da shape\n",
            "-1.2197443969790327\n",
            "da shape\n",
            "2.4493686490613973\n",
            "da shape\n",
            "-0.5457741679825677\n",
            "da shape\n",
            "-0.19883786288889674\n",
            "da shape\n",
            "-0.7003985049212547\n",
            "da shape\n",
            "-0.20339444896455844\n",
            "mode = average\n",
            "mean of dA =  0.14571390272918056\n",
            "dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]\n",
            " [ 1.26461098 -0.25749373]\n",
            " [ 1.17975636 -0.53624893]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}